#!/usr/bin/env python3
"""
æµ‹è¯•CLIP ViT-L/14åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶

è¯¥è„šæœ¬ä¼šæµ‹è¯•é™¤äº†country211ã€imagenetv2ã€sun397ã€objectnetå’Œeurosatå¤–çš„æ‰€æœ‰æ”¯æŒæ•°æ®é›†ï¼Œ
ä¸é™åˆ¶æ ·æœ¬æ•°é‡ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶ä¸­ã€‚
"""

import argparse
import json
import os
import time
from datetime import datetime
from pathlib import Path

import pandas as pd
import torch

from main import (
    DATASET_CLASSES,
    evaluate_dataset,
    load_clip_model,
    setup_device,
    setup_dtype,
    create_directories
)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æµ‹è¯•CLIP ViT-L/14åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument(
        "--data-root",
        type=str,
        default="./data",
        help="æ•°æ®é›†æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--model-root",
        type=str,
        default="./model_weights",
        help="CLIP æ¨¡å‹æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./results",
        help="ç»“æœè¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="æ‰¹å¤„ç†å¤§å°"
    )
    
    parser.add_argument(
        "--num-workers",
        type=int,
        default=4,
        help="æ•°æ®åŠ è½½å™¨çš„å·¥ä½œè¿›ç¨‹æ•°"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)"
    )
    
    parser.add_argument(
        "--dtype",
        type=str,
        default="auto",
        help="æ•°æ®ç±»å‹ (auto/fp16/fp32)"
    )
    
    parser.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="è®¡ç®— top-k å‡†ç¡®ç‡"
    )
    
    parser.add_argument(
        "--excel-name",
        type=str,
        default=None,
        help="Excelæ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³"
    )
    
    return parser.parse_args()


def save_results_to_excel(results, output_dir, excel_name=None):
    """å°†è¯„ä¼°ç»“æœä¿å­˜åˆ°Excelæ–‡ä»¶"""
    if excel_name is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_name = f"clip_evaluation_{timestamp}"
    
    excel_path = os.path.join(output_dir, f"{excel_name}.xlsx")
    
    # å‡†å¤‡æ•°æ®
    data = []
    for result in results:
        if "error" in result:
            # å¤„ç†å¤±è´¥çš„æƒ…å†µ
            data.append({
                "æ•°æ®é›†": result["dataset"],
                "æ ·æœ¬æ•°é‡": "N/A",
                "ç±»åˆ«æ•°é‡": "N/A",
                "Top-1 å‡†ç¡®ç‡": "N/A",
                f"Top-{result.get('top_k', 5)} å‡†ç¡®ç‡": "N/A",
                "æ¨ç†æ—¶é—´(ç§’)": "N/A",
                "å¤„ç†é€Ÿåº¦(æ ·æœ¬/ç§’)": "N/A",
                "çŠ¶æ€": "å¤±è´¥",
                "é”™è¯¯ä¿¡æ¯": result["error"]
            })
        else:
            # å¤„ç†æˆåŠŸçš„æƒ…å†µ
            top_k = result.get('top_k', 5)
            data.append({
                "æ•°æ®é›†": result["dataset"],
                "æ ·æœ¬æ•°é‡": result["num_samples"],
                "ç±»åˆ«æ•°é‡": result["num_classes"],
                "Top-1 å‡†ç¡®ç‡": f"{result['top1_accuracy']:.4f}",
                f"Top-{top_k} å‡†ç¡®ç‡": f"{result[f'top{top_k}_accuracy']:.4f}",
                "æ¨ç†æ—¶é—´(ç§’)": f"{result['inference_time']:.2f}",
                "å¤„ç†é€Ÿåº¦(æ ·æœ¬/ç§’)": f"{result['samples_per_second']:.2f}",
                "çŠ¶æ€": "æˆåŠŸ",
                "é”™è¯¯ä¿¡æ¯": ""
            })
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    
    # ä¿å­˜åˆ°Excel
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='è¯„ä¼°ç»“æœ', index=False)
        
        # è·å–å·¥ä½œè¡¨å¯¹è±¡
        worksheet = writer.sheets['è¯„ä¼°ç»“æœ']
        
        # è°ƒæ•´åˆ—å®½
        for column in worksheet.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 30)
            worksheet.column_dimensions[column_letter].width = adjusted_width
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°Excelæ–‡ä»¶: {excel_path}")
    
    # æ‰“å°æ‘˜è¦
    successful = len([r for r in results if "error" not in r])
    failed = len([r for r in results if "error" in r])
    
    print("\nğŸ“‹ è¯„ä¼°æ‘˜è¦:")
    print(f"æ€»æ•°æ®é›†æ•°: {len(results)}")
    print(f"æˆåŠŸè¯„ä¼°: {successful}")
    print(f"å¤±è´¥è¯„ä¼°: {failed}")
    
    if successful > 0:
        print("\nğŸ† æœ€ä½³ç»“æœ (Top-1 å‡†ç¡®ç‡):")
        successful_results = [r for r in results if "error" not in r]
        successful_results.sort(key=lambda x: x.get("top1_accuracy", 0), reverse=True)
        
        for i, result in enumerate(successful_results[:5]):
            print(f"{i+1}. {result['dataset']}: {result.get('top1_accuracy', 0):.4f}")
    
    return excel_path


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device(args.device)
    
    # è®¾ç½®æ•°æ®ç±»å‹
    dtype = setup_dtype(args.dtype, device)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    create_directories(args.output_dir)
    
    # è·å–æ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†ï¼Œæ’é™¤country211ã€imagenetv2ã€sun397ã€objectnetå’Œeurosat
    all_datasets = list(DATASET_CLASSES.keys())
    exclude_datasets = ["country211", "imagenet_v2", "sun397", "objectnet", "eurosat"]
    dataset_names = [d for d in all_datasets if d not in exclude_datasets]
    
    print(f"ğŸ¯ å°†è¯„ä¼°ä»¥ä¸‹æ•°æ®é›† (æ’é™¤ {exclude_datasets}): {', '.join(dataset_names)}")
    
    # åŠ è½½ CLIP æ¨¡å‹
    print("\nğŸ¤– åŠ è½½ CLIP æ¨¡å‹...")
    try:
        model, processor = load_clip_model(args.model_root, device, dtype)
    except Exception as e:
        print(f"âŒ åŠ è½½ CLIP æ¨¡å‹å¤±è´¥: {str(e)}")
        return
    
    # è¯„ä¼°æ‰€æœ‰æ•°æ®é›†
    results = []
    start_time = time.time()
    
    for i, dataset_name in enumerate(dataset_names):
        print(f"\nğŸ“Š [{i+1}/{len(dataset_names)}] å¼€å§‹è¯„ä¼°æ•°æ®é›†: {dataset_name}")
        
        result = evaluate_dataset(
            model=model,
            processor=processor,
            dataset_name=dataset_name,
            data_root=args.data_root,
            batch_size=args.batch_size,
            num_workers=args.num_workers,
            device=device,
            limit=None,  # ä¸é™åˆ¶æ ·æœ¬æ•°é‡
            top_k=args.top_k
        )
        result['top_k'] = args.top_k  # ä¿å­˜top_kå€¼
        results.append(result)
    
    total_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è¯„ä¼°æ—¶é—´: {total_time:.2f} ç§’")
    
    # ä¿å­˜ç»“æœåˆ°Excel
    excel_path = save_results_to_excel(results, args.output_dir, args.excel_name)
    
    print("\nğŸ‰ è¯„ä¼°å®Œæˆ!")
    return excel_path


if __name__ == "__main__":
    main()