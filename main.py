#!/usr/bin/env python3
"""
CLIP ViT-L/14 é›¶æ ·æœ¬è¯„ä¼°è„šæœ¬

è¯¥è„šæœ¬ç”¨äºè¯„ä¼° CLIP ViT-L/14 æ¨¡å‹åœ¨å¤šä¸ªè§†è§‰æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬åˆ†ç±»æ€§èƒ½ã€‚
æ”¯æŒè‡ªåŠ¨æ£€æµ‹ GPUã€æ‰¹å¤„ç†æ¨ç†ã€è¿›åº¦æ˜¾ç¤ºå’Œç»“æœä¿å­˜ã€‚

ä½¿ç”¨ç¤ºä¾‹:
    python main.py --datasets cifar10,imagenet1k --data-root ./data --model-root ./model_weights --output-dir ./results
    python main.py --datasets all --batch-size 64 --num-workers 4
"""

import argparse
import json
import os
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets as tv_datasets, transforms
from tqdm import tqdm
from PIL import Image
import pickle

# æ•°æ®é›†ç±»åæ˜ å°„
DATASET_CLASSES = {
    "cifar10": [
        "airplane", "automobile", "bird", "cat", "deer",
        "dog", "frog", "horse", "ship", "truck"
    ],
    "cifar100": [f"class_{i}" for i in range(100)],  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ä½¿ç”¨çœŸå®ç±»å
    "mnist": [str(i) for i in range(10)],
    "imagenet1k": [f"imagenet_class_{i}" for i in range(1000)],  # å°†åœ¨åŠ è½½æ—¶æ›´æ–°ä¸ºå®é™…ç±»åˆ«åç§°
    "caltech101": [f"caltech101_class_{i}" for i in range(101)],  # ç®€åŒ–å¤„ç†
    "stanford_cars": [f"car_model_{i}" for i in range(196)],  # ç®€åŒ–å¤„ç†
    "flowers102": [f"flower_{i}" for i in range(102)],  # ç®€åŒ–å¤„ç†
    "food101": [f"food_{i}" for i in range(101)],  # ç®€åŒ–å¤„ç†
    "pets": [f"pet_{i}" for i in range(37)],  # ç®€åŒ–å¤„ç†
    "sun397": [f"scene_{i}" for i in range(397)],  # ç®€åŒ–å¤„ç†
    "dtd": [f"texture_{i}" for i in range(47)],  # ç®€åŒ–å¤„ç†
    "gtsrb": [f"traffic_sign_{i}" for i in range(43)],  # ç®€åŒ–å¤„ç†
    "stl10": [f"stl10_class_{i}" for i in range(10)],  # ç®€åŒ–å¤„ç†
    "voc2007": [f"voc_object_{i}" for i in range(20)],  # ç®€åŒ–å¤„ç†
    "country211": [f"country_{i}" for i in range(211)],  # ç®€åŒ–å¤„ç†
    "eurosat": [f"land_use_{i}" for i in range(10)],  # ç®€åŒ–å¤„ç†
    "fer2013": [f"emotion_{i}" for i in range(7)],  # ç®€åŒ–å¤„ç†
    "resisc45": [f"scene_{i}" for i in range(45)],  # ç®€åŒ–å¤„ç†
    "rendered_sst2": ["negative", "positive"],
    "imagenet_v2": [f"imagenet_v2_class_{i}" for i in range(1000)],  # ç®€åŒ–å¤„ç†
    "imagenet_adv": [f"imagenet_adv_class_{i}" for i in range(1000)],  # ç®€åŒ–å¤„ç†
    "imagenet_ren": [f"imagenet_ren_class_{i}" for i in range(200)],  # ç®€åŒ–å¤„ç†
    "imagenet_ske": [f"imagenet_ske_class_{i}" for i in range(1000)],  # ç®€åŒ–å¤„ç†
    "objectnet": [f"object_{i}" for i in range(313)],  # ç®€åŒ–å¤„ç†
    "fgvc_aircraft": [f"aircraft_{i}" for i in range(100)],  # ç®€åŒ–å¤„ç†
}


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="CLIP ViT-L/14 é›¶æ ·æœ¬è¯„ä¼°è„šæœ¬",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument(
        "--datasets",
        type=str,
        default="cifar10,cifar100,mnist",
        help="è¦è¯„ä¼°çš„æ•°æ®é›†åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œæˆ–ä½¿ç”¨ 'all' è¯„ä¼°æ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†"
    )
    
    parser.add_argument(
        "--model-root",
        type=str,
        default="./model_weights",
        help="CLIP æ¨¡å‹æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--data-root",
        type=str,
        default="./data",
        help="æ•°æ®é›†æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./results",
        help="ç»“æœè¾“å‡ºç›®å½•"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="æ‰¹å¤„ç†å¤§å°"
    )
    
    parser.add_argument(
        "--num-workers",
        type=int,
        default=4,
        help="æ•°æ®åŠ è½½å™¨çš„å·¥ä½œè¿›ç¨‹æ•°"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="è®¡ç®—è®¾å¤‡ (auto/cuda/cpu)"
    )
    
    parser.add_argument(
        "--dtype",
        type=str,
        default="auto",
        help="æ•°æ®ç±»å‹ (auto/fp16/fp32)"
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶æ¯ä¸ªæ•°æ®é›†çš„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰"
    )
    
    parser.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="è®¡ç®— top-k å‡†ç¡®ç‡"
    )
    
    return parser.parse_args()


def setup_device(device_arg: str) -> torch.device:
    """è®¾ç½®è®¡ç®—è®¾å¤‡"""
    if device_arg == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
            print(f"âœ… ä½¿ç”¨ GPU: {torch.cuda.get_device_name()}")
        else:
            device = torch.device("cpu")
            print("âš ï¸  æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU")
    else:
        device = torch.device(device_arg)
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
    
    return device


def setup_dtype(dtype_arg: str, device: torch.device) -> torch.dtype:
    """è®¾ç½®æ•°æ®ç±»å‹"""
    if dtype_arg == "auto":
        if device.type == "cuda":
            dtype = torch.float16
            print("âœ… ä½¿ç”¨ FP16 ç²¾åº¦")
        else:
            dtype = torch.float32
            print("âœ… ä½¿ç”¨ FP32 ç²¾åº¦")
    else:
        if dtype_arg == "fp16":
            dtype = torch.float16
        elif dtype_arg == "fp32":
            dtype = torch.float32
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {dtype_arg}")
        print(f"âœ… ä½¿ç”¨ {dtype_arg.upper()} ç²¾åº¦")
    
    return dtype


def create_directories(output_dir: str) -> None:
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    print(f"âœ… ç»“æœå°†ä¿å­˜åˆ°: {output_dir}")


def get_available_datasets(data_root: str) -> List[str]:
    """è·å– data æ–‡ä»¶å¤¹ä¸­å¯ç”¨çš„æ•°æ®é›†åˆ—è¡¨"""
    data_path = Path(data_root)
    if not data_path.exists():
        print(f"âš ï¸  æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return []
    
    # è·å–æ‰€æœ‰å­ç›®å½•
    subdirs = [d.name for d in data_path.iterdir() if d.is_dir()]
    
    # è¿‡æ»¤å‡ºæ”¯æŒçš„æ•°æ®é›†
    available_datasets = []
    for subdir in subdirs:
        if subdir in DATASET_CLASSES:
            available_datasets.append(subdir)
        else:
            print(f"âš ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®é›†: {subdir}")
    
    return sorted(available_datasets)


class CIFAR10Dataset(Dataset):
    """CIFAR-10 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, train: bool = False, transform=None):
        self.transform = transform
        self.data_path = data_path
        
        # åŠ è½½ CIFAR-10 æ•°æ®
        cifar_path = os.path.join(data_path, "cifar-10-batches-py")
        if train:
            # åŠ è½½è®­ç»ƒæ•°æ®
            self.data = []
            self.labels = []
            for i in range(1, 6):
                batch_path = os.path.join(cifar_path, f"data_batch_{i}")
                with open(batch_path, 'rb') as f:
                    batch = pickle.load(f, encoding='bytes')
                    self.data.append(batch[b'data'])
                    self.labels.extend(batch[b'labels'])
            self.data = np.concatenate(self.data)
        else:
            # åŠ è½½æµ‹è¯•æ•°æ®
            batch_path = os.path.join(cifar_path, "test_batch")
            with open(batch_path, 'rb') as f:
                batch = pickle.load(f, encoding='bytes')
                self.data = batch[b'data']
                self.labels = batch[b'labels']
        
        # é‡å¡‘æ•°æ®ä¸º (N, 3, 32, 32)
        self.data = self.data.reshape(len(self.data), 3, 32, 32)
        self.data = self.data.transpose(0, 2, 3, 1)  # è½¬æ¢ä¸º (N, 32, 32, 3)
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img = self.data[idx]
        label = self.labels[idx]
        
        # è½¬æ¢ä¸º PIL Image
        img = Image.fromarray(img)
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class CIFAR100Dataset(Dataset):
    """CIFAR-100 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, train: bool = False, transform=None):
        self.transform = transform
        self.data_path = data_path
        
        # åŠ è½½ CIFAR-100 æ•°æ®
        cifar_path = os.path.join(data_path, "cifar-100-python")
        if train:
            batch_path = os.path.join(cifar_path, "train")
        else:
            batch_path = os.path.join(cifar_path, "test")
            
        with open(batch_path, 'rb') as f:
            batch = pickle.load(f, encoding='bytes')
            self.data = batch[b'data']
            self.labels = batch[b'fine_labels']
        
        # é‡å¡‘æ•°æ®ä¸º (N, 3, 32, 32)
        self.data = self.data.reshape(len(self.data), 3, 32, 32)
        self.data = self.data.transpose(0, 2, 3, 1)  # è½¬æ¢ä¸º (N, 32, 32, 3)
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img = self.data[idx]
        label = self.labels[idx]
        
        # è½¬æ¢ä¸º PIL Image
        img = Image.fromarray(img)
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class MNISTRawFallbackDataset(Dataset):
    """å½“ torchvision å¤„ç†è¿‡çš„ MNIST æ–‡ä»¶ç¼ºå¤±æ—¶çš„åå¤‡åŠ è½½å™¨"""

    def __init__(self, raw_root: str, split: str = "test", transform=None):
        self.transform = transform
        if split == "train":
            prefix = "train"
        elif split == "test":
            prefix = "t10k"
        else:
            raise ValueError(f"MNISTRawFallbackDataset ä¸æ”¯æŒçš„ split: {split}")

        images_path = os.path.join(raw_root, f"{prefix}-images-idx3-ubyte")
        labels_path = os.path.join(raw_root, f"{prefix}-labels-idx1-ubyte")

        self.data = self._load_images(images_path)
        self.labels = self._load_labels(labels_path)

        if self.data.shape[0] != self.labels.shape[0]:
            raise ValueError("MNIST å›¾åƒä¸æ ‡ç­¾æ•°é‡ä¸ä¸€è‡´")

    @staticmethod
    def _resolve_path(base_path: str) -> str:
        if os.path.exists(base_path):
            return base_path
        gz_path = base_path + ".gz"
        if os.path.exists(gz_path):
            return gz_path
        raise FileNotFoundError(f"æœªæ‰¾åˆ° MNIST æ–‡ä»¶: {base_path}(.gz)")

    @classmethod
    def _load_images(cls, base_path: str) -> np.ndarray:
        import gzip
        import struct

        path = cls._resolve_path(base_path)
        opener = gzip.open if path.endswith(".gz") else open
        with opener(path, "rb") as f:
            magic, num, rows, cols = struct.unpack(">IIII", f.read(16))
            if magic != 2051:
                raise ValueError(f"æ— æ•ˆçš„ MNIST å›¾åƒæ–‡ä»¶é­”æ•°: {magic}")
            data = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)
        return data

    @classmethod
    def _load_labels(cls, base_path: str) -> np.ndarray:
        import gzip
        import struct

        path = cls._resolve_path(base_path)
        opener = gzip.open if path.endswith(".gz") else open
        with opener(path, "rb") as f:
            magic, num = struct.unpack(">II", f.read(8))
            if magic != 2049:
                raise ValueError(f"æ— æ•ˆçš„ MNIST æ ‡ç­¾æ–‡ä»¶é­”æ•°: {magic}")
            labels = np.frombuffer(f.read(), dtype=np.uint8)
        return labels

    def __len__(self) -> int:
        return len(self.data)

    def __getitem__(self, idx: int):
        img = Image.fromarray(self.data[idx], mode="L").convert("RGB")
        label = int(self.labels[idx])
        if self.transform:
            img = self.transform(img)
        return img, label


class Caltech101Dataset(Dataset):
    """Caltech-101 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_to_idx = {}
        
        # Caltech-101 ç‰¹æ®Šè·¯å¾„ç»“æ„
        image_folder_path = os.path.join(data_path, "caltech101", "101_ObjectCategories")
        if not os.path.exists(image_folder_path):
            raise FileNotFoundError(f"Caltech-101 å›¾åƒæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_folder_path}")
        
        print(f"ğŸ” æ‰«æ Caltech-101 å›¾åƒæ–‡ä»¶å¤¹: {image_folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        classes = []
        for item in os.listdir(image_folder_path):
            item_path = os.path.join(image_folder_path, item)
            if os.path.isdir(item_path):
                classes.append(item)
        
        classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"ğŸ“ æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes[:5]}{'...' if len(classes) > 5 else ''}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for class_name in classes:
            class_dir = os.path.join(image_folder_path, class_name)
            class_idx = self.class_to_idx[class_name]
            
            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
            
            for img_name in img_files:
                img_path = os.path.join(class_dir, img_name)
                self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class StanfordCarsDataset(Dataset):
    """Stanford Cars æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None, limit=None):
        self.transform = transform
        self.samples = []
        self.class_names = []
        
        # Stanford Cars æ•°æ®é›†è·¯å¾„
        cars_root = os.path.join(data_path, "stanford_cars")
        if not os.path.exists(cars_root):
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            possible_paths = [
                os.path.join(data_path, "stanford_cars", "stanford_cars"),
                data_path
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    cars_root = path
                    break
            else:
                raise FileNotFoundError(f"Stanford Carsæ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {cars_root}")
        
        print(f"ğŸ” æ‰«æ Stanford Cars æ•°æ®é›†: {cars_root}")
        
        # åŠ è½½ç±»åˆ«åç§°
        meta_path = os.path.join(cars_root, "devkit", "cars_meta.mat")
        if os.path.exists(meta_path):
            try:
                import scipy.io
                meta_data = scipy.io.loadmat(meta_path)
                # è·å–å®é™…çš„ç±»åˆ«åç§°
                self.class_names = [name[0] for name in meta_data['class_names'][0]]
                print(f"âœ… ä»å…ƒæ•°æ®æ–‡ä»¶åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åŠ è½½ç±»åˆ«å…ƒæ•°æ®æ–‡ä»¶: {e}")
                self.class_names = [f"Car Model {i+1}" for i in range(196)]
        else:
            print(f"âš ï¸  ç±»åˆ«å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {meta_path}")
            self.class_names = [f"Car Model {i+1}" for i in range(196)]
        
        # å°è¯•åŠ è½½æµ‹è¯•é›†çš„æ ‡æ³¨æ–‡ä»¶
        test_annos_path = os.path.join(cars_root, "cars_test_annos_withlabels.mat")
        test_dir = os.path.join(cars_root, "cars_test")
        
        if os.path.exists(test_annos_path) and os.path.exists(test_dir):
            try:
                import scipy.io
                # åŠ è½½æ ‡æ³¨æ–‡ä»¶
                annotations = scipy.io.loadmat(test_annos_path)
                test_annotations = annotations['annotations'][0]
                
                # å¤„ç†æ¯ä¸ªæµ‹è¯•å›¾åƒ
                for anno in test_annotations:
                    # è·å–å›¾åƒæ–‡ä»¶åå’Œæ ‡ç­¾
                    img_filename = anno[-1][0]  # å›¾åƒæ–‡ä»¶ååœ¨æœ€åä¸€ä¸ªä½ç½®
                    label = int(anno[-2][0] - 1)  # MATLABç´¢å¼•ä»1å¼€å§‹ï¼Œè½¬æ¢ä¸º0å¼€å§‹
                    
                    img_path = os.path.join(test_dir, img_filename)
                    if os.path.exists(img_path):
                        self.samples.append((img_path, label))
                
                print(f"ğŸ“ ä»æ ‡æ³¨æ–‡ä»¶åŠ è½½äº† {len(self.samples)} ä¸ªæµ‹è¯•å›¾åƒ")
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åŠ è½½æ ‡æ³¨æ–‡ä»¶: {e}")
                # å›é€€åˆ°ç®€å•çš„æ–‡ä»¶å¤¹æ‰«æ
                self._fallback_load(cars_root, limit)
        else:
            # å›é€€åˆ°ç®€å•çš„æ–‡ä»¶å¤¹æ‰«æ
            self._fallback_load(cars_root, limit)
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
        print(f"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {len(self.class_names)}")
        
        # é™åˆ¶æ ·æœ¬æ•°é‡
        if limit is not None and limit < len(self.samples):
            self.samples = self.samples[:limit]
            print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
    
    def _fallback_load(self, cars_root, limit=None):
        """å›é€€åŠ è½½æ–¹æ³•ï¼Œå½“æ— æ³•åŠ è½½æ ‡æ³¨æ–‡ä»¶æ—¶ä½¿ç”¨"""
        print("ğŸ”„ ä½¿ç”¨å›é€€æ–¹æ³•åŠ è½½æ•°æ®...")
        
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for subdir in ["cars_test", "cars_train"]:
            subdir_path = os.path.join(cars_root, subdir)
            if os.path.exists(subdir_path):
                img_files = [f for f in os.listdir(subdir_path)
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                
                for img_file in img_files:
                    img_path = os.path.join(subdir_path, img_file)
                    # ä½¿ç”¨ç®€å•çš„ç±»åˆ«æ ‡ç­¾
                    self.samples.append((img_path, 0 if subdir == "cars_test" else 1))
        
        # ä½¿ç”¨ç®€å•çš„ç±»åˆ«åç§°
        self.class_names = ["Test Cars", "Train Cars"]
        
        # é™åˆ¶æ ·æœ¬æ•°é‡
        if limit is not None and limit < len(self.samples):
            self.samples = self.samples[:limit]
            print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if label >= len(self.class_names):
            label = 0
        
        # åŠ è½½å›¾åƒ
        image = Image.open(img_path).convert('RGB')
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    @property
    def class_to_idx(self):
        """ä¸ºäº†å…¼å®¹æ€§ï¼Œæä¾›class_to_idxå±æ€§"""
        return {name: i for i, name in enumerate(self.class_names)}


class Flowers102Dataset(Dataset):
    """Flowers-102 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_names = []
        
        # Flowers-102 æ•°æ®é›†ç»“æ„
        # å›¾åƒåœ¨ ./data/flowers102/flowers-102/jpg/ ç›®å½•ä¸‹
        # æ ‡ç­¾åœ¨ ./data/flowers102/flowers-102/imagelabels.mat æ–‡ä»¶ä¸­
        
        # æŸ¥æ‰¾æ•°æ®é›†ç›®å½•
        dataset_dir = None
        for item in os.listdir(data_path):
            item_path = os.path.join(data_path, item)
            if os.path.isdir(item_path) and "flowers-102" in item.lower():
                dataset_dir = item_path
                break
        
        if dataset_dir is None:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°Flowers-102æ•°æ®é›†ç›®å½•åœ¨ {data_path}")
        
        # å›¾åƒç›®å½•
        images_dir = os.path.join(dataset_dir, "jpg")
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"Flowers-102å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        
        # æ ‡ç­¾æ–‡ä»¶
        labels_file = os.path.join(dataset_dir, "imagelabels.mat")
        if not os.path.exists(labels_file):
            raise FileNotFoundError(f"Flowers-102æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {labels_file}")
        
        # åŠ è½½æ ‡ç­¾
        import scipy.io
        labels_data = scipy.io.loadmat(labels_file)
        # imagelabels.matåŒ…å«ä¸€ä¸ªåä¸º'labels'çš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(1, N)ï¼Œå…¶ä¸­Næ˜¯å›¾åƒæ•°é‡
        labels = labels_data['labels'][0]  # è·å–æ ‡ç­¾æ•°ç»„
        
        # Flowers-102ç±»åˆ«åç§°ï¼ˆ102ç§èŠ±ï¼‰
        self.class_names = [
            "pink primrose", "hard-leaved pocket orchid", "canterbury bells", "sweet pea", "english marigold",
            "tiger lily", "moon orchid", "bird of paradise", "monkshood", "globe thistle",
            "snapdragon", "colts' foot", "king protea", "spear thistle", "yellow iris",
            "globe-flower", "purple coneflower", "peruvian lily", "balloon flower", "giant white arum lily",
            "fire lily", "pincushion flower", "fritillary", "red ginger", "grape hyacinth",
            "corn poppy", "prince of wales feathers", "stemless gentian", "artichoke", "sweet william",
            "carnation", "garden phlox", "love in the mist", "mexican aster", "alpine sea holly",
            "ruby-lipped cattleya", "cape flower", "masterwort", "siam tulip", "lenten rose",
            "barbeton daisy", "daffodil", "sword lily", "poinsettia", "bolero deep blue",
            "wallflower", "marigold", "buttercup", "oxeye daisy", "common dandelion",
            "petunia", "wild pansy", "primula", "sunflower", "pelargonium",
            "bishop of llandaff", "gaura", "geranium", "orange dahlia", "pink-yellow dahlia",
            "cautleya spicata", "japanese anemone", "black-eyed susan", "silverbush", "french marigold",
            "bromelia", "blanket flower", "trumpet creeper", "camellia", "mallow",
            "mexican petunia", "bougainvillea", "water lily", "rose", "thorn apple",
            "morning glory", "passion flower", "lotus", "toad lily", "anthurium",
            "frangipani", "clematis", "hibiscus", "columbine", "desert-rose",
            "tree mallow", "magnolia", "cyclamen", "watercress", "canna lily",
            "hippeastrum", "bee balm", "ball moss", "foxglove", "bougainvillea",
            "camellia", "mallow", "mexican petunia", "bougainvillea", "water lily",
            "rose", "thorn apple", "morning glory", "passion flower", "lotus"
        ]
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶å¹¶æ’åº
        img_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        img_files.sort()  # ç¡®ä¿å›¾åƒæ–‡ä»¶æŒ‰åç§°æ’åºï¼Œä¸æ ‡ç­¾å¯¹åº”
        
        # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
        for i, img_file in enumerate(img_files):
            if i < len(labels):
                # Flowers-102çš„æ ‡ç­¾ä»1å¼€å§‹ï¼Œéœ€è¦è½¬æ¢ä¸º0å¼€å§‹çš„ç´¢å¼•
                label_idx = int(labels[i]) - 1
                if 0 <= label_idx < len(self.class_names):
                    img_path = os.path.join(images_dir, img_file)
                    self.samples.append((img_path, label_idx))
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªæ ·æœ¬")
        print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label
    
    def get_classes(self):
        return self.class_names


class Food101Dataset(Dataset):
    """Food-101 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_names = []
        
        # Food-101 æ•°æ®é›†è·¯å¾„
        food101_path = os.path.join(data_path, "food-101")
        if not os.path.exists(food101_path):
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            possible_paths = [
                os.path.join(data_path, "food101"),
                data_path
            ]
            for path in possible_paths:
                if os.path.exists(path):
                    food101_path = path
                    break
            else:
                raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° Food-101 æ•°æ®é›†ç›®å½•")
        
        print(f"ğŸ” æ‰«æ Food-101 æ•°æ®é›†: {food101_path}")
        
        # åŠ è½½ç±»åˆ«åç§°
        classes_file = os.path.join(food101_path, "meta", "classes.txt")
        if not os.path.exists(classes_file):
            raise FileNotFoundError(f"Food-101 ç±»åˆ«æ–‡ä»¶ä¸å­˜åœ¨: {classes_file}")
        
        with open(classes_file, 'r') as f:
            self.class_names = [line.strip() for line in f.readlines()]
        
        print(f"ğŸ“ åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
        print(f"ğŸ“ å‰5ä¸ªç±»åˆ«: {self.class_names[:5]}")
        
        # åˆ›å»ºç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„
        class_to_idx = {cls_name: i for i, cls_name in enumerate(self.class_names)}
        
        # åŠ è½½æµ‹è¯•é›†åˆ—è¡¨
        test_file = os.path.join(food101_path, "meta", "test.txt")
        if not os.path.exists(test_file):
            raise FileNotFoundError(f"Food-101 æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        
        with open(test_file, 'r') as f:
            test_lines = [line.strip() for line in f.readlines()]
        
        # å›¾åƒç›®å½•
        images_dir = os.path.join(food101_path, "images")
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"Food-101 å›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        
        # å¤„ç†æµ‹è¯•é›†
        for line in test_lines:
            # æ ¼å¼: ç±»åˆ«å/å›¾åƒID
            if '/' in line:
                class_name, img_id = line.split('/', 1)
                if class_name in class_to_idx:
                    class_idx = class_to_idx[class_name]
                    img_path = os.path.join(images_dir, class_name, f"{img_id}.jpg")
                    if os.path.exists(img_path):
                        self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªæµ‹è¯•å›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label
    
    def get_classes(self):
        return self.class_names


class PetsDataset(Dataset):
    """Oxford-IIIT Pets æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_names = []
        
        # Oxford-IIIT Pets æ•°æ®é›†ç»“æ„
        # å›¾åƒåœ¨ ./data/pets/oxford-iiit-pet/images/ ç›®å½•ä¸‹
        # æ ‡æ³¨åœ¨ ./data/pets/oxford-iiit-pet/annotations/xmls/ ç›®å½•ä¸‹
        
        # æŸ¥æ‰¾æ•°æ®é›†ç›®å½•
        dataset_dir = None
        for item in os.listdir(data_path):
            item_path = os.path.join(data_path, item)
            if os.path.isdir(item_path) and "oxford-iiit-pet" in item.lower():
                dataset_dir = item_path
                break
        
        if dataset_dir is None:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°Oxford-IIIT Petsæ•°æ®é›†ç›®å½•åœ¨ {data_path}")
        
        # å›¾åƒç›®å½•
        images_dir = os.path.join(dataset_dir, "images")
        if not os.path.exists(images_dir):
            raise FileNotFoundError(f"Oxford-IIIT Petså›¾åƒç›®å½•ä¸å­˜åœ¨: {images_dir}")
        
        # æ ‡æ³¨ç›®å½•
        annotations_dir = os.path.join(dataset_dir, "annotations", "xmls")
        if not os.path.exists(annotations_dir):
            raise FileNotFoundError(f"Oxford-IIIT Petsæ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {annotations_dir}")
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        # ä»å›¾åƒæ–‡ä»¶åæå–ç±»åˆ«åç§°
        # Oxford-IIIT Petsçš„å›¾åƒæ–‡ä»¶åæ ¼å¼ä¸º: breed_XXX.jpg
        breed_names = set()
        for img_file in image_files:
            # æå–å“ç§åç§°ï¼ˆä¸‹åˆ’çº¿å‰çš„éƒ¨åˆ†ï¼‰
            breed_name = "_".join(img_file.split("_")[:-1])
            breed_names.add(breed_name)
        
        # æ’åºå¹¶åˆ›å»ºç±»åˆ«æ˜ å°„
        self.class_names = sorted(list(breed_names))
        class_to_idx = {breed: i for i, breed in enumerate(self.class_names)}
        
        print(f"âœ… ä»å›¾åƒæ–‡ä»¶åæå–äº† {len(self.class_names)} ä¸ªç±»åˆ«")
        
        # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
        for img_file in image_files:
            # æå–å“ç§åç§°
            breed_name = "_".join(img_file.split("_")[:-1])
            
            if breed_name in class_to_idx:
                img_path = os.path.join(images_dir, img_file)
                class_idx = class_to_idx[breed_name]
                self.samples.append((img_path, class_idx))
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label
    
    @property
    def class_to_idx(self):
        """ä¸ºäº†å…¼å®¹æ€§ï¼Œæä¾›class_to_idxå±æ€§"""
        return {name: i for i, name in enumerate(self.class_names)}


class DTDataset(Dataset):
    """Describable Textures Dataset (DTD) æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_to_idx = {}
        
        # DTD å¯èƒ½çš„è·¯å¾„ç»“æ„
        possible_paths = [
            os.path.join(data_path, "test"),
            os.path.join(data_path, "dtd"),
            os.path.join(data_path, "images"),
            data_path
        ]
        
        image_folder_path = None
        for path in possible_paths:
            if os.path.exists(path):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ç›®å½•
                subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
                if subdirs:
                    image_folder_path = path
                    break
        
        if image_folder_path is None:
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° DTD çš„å›¾åƒæ–‡ä»¶å¤¹")
        
        print(f"ğŸ” æ‰«æ DTD å›¾åƒæ–‡ä»¶å¤¹: {image_folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        classes = []
        for item in os.listdir(image_folder_path):
            item_path = os.path.join(image_folder_path, item)
            if os.path.isdir(item_path):
                classes.append(item)
        
        classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"ğŸ“ æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes[:5]}{'...' if len(classes) > 5 else ''}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for class_name in classes:
            class_dir = os.path.join(image_folder_path, class_name)
            class_idx = self.class_to_idx[class_name]
            
            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
            
            for img_name in img_files:
                img_path = os.path.join(class_dir, img_name)
                self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class GTSRBDataset(Dataset):
    """German Traffic Sign Recognition Benchmark (GTSRB) æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_to_idx = {}
        
        # GTSRB å¯èƒ½çš„è·¯å¾„ç»“æ„
        possible_paths = [
            os.path.join(data_path, "test"),
            os.path.join(data_path, "gtsrb"),
            os.path.join(data_path, "images"),
            data_path
        ]
        
        image_folder_path = None
        for path in possible_paths:
            if os.path.exists(path):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ç›®å½•
                subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
                if subdirs:
                    image_folder_path = path
                    break
        
        if image_folder_path is None:
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° GTSRB çš„å›¾åƒæ–‡ä»¶å¤¹")
        
        print(f"ğŸ” æ‰«æ GTSRB å›¾åƒæ–‡ä»¶å¤¹: {image_folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        classes = []
        for item in os.listdir(image_folder_path):
            item_path = os.path.join(image_folder_path, item)
            if os.path.isdir(item_path):
                classes.append(item)
        
        classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"ğŸ“ æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes[:5]}{'...' if len(classes) > 5 else ''}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for class_name in classes:
            class_dir = os.path.join(image_folder_path, class_name)
            class_idx = self.class_to_idx[class_name]
            
            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
            
            for img_name in img_files:
                img_path = os.path.join(class_dir, img_name)
                self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class STL10Dataset(Dataset):
    """STL-10 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_to_idx = {}
        
        # STL-10 å¯èƒ½çš„è·¯å¾„ç»“æ„
        possible_paths = [
            os.path.join(data_path, "test"),
            os.path.join(data_path, "stl10"),
            os.path.join(data_path, "images"),
            data_path
        ]
        
        image_folder_path = None
        for path in possible_paths:
            if os.path.exists(path):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ç›®å½•
                subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
                if subdirs:
                    image_folder_path = path
                    break
        
        if image_folder_path is None:
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° STL-10 çš„å›¾åƒæ–‡ä»¶å¤¹")
        
        print(f"ğŸ” æ‰«æ STL-10 å›¾åƒæ–‡ä»¶å¤¹: {image_folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        classes = []
        for item in os.listdir(image_folder_path):
            item_path = os.path.join(image_folder_path, item)
            if os.path.isdir(item_path):
                classes.append(item)
        
        classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"ğŸ“ æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes[:5]}{'...' if len(classes) > 5 else ''}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for class_name in classes:
            class_dir = os.path.join(image_folder_path, class_name)
            class_idx = self.class_to_idx[class_name]
            
            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
            
            for img_name in img_files:
                img_path = os.path.join(class_dir, img_name)
                self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class SUN397Dataset(Dataset):
    """SUN397 æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_to_idx = {}
        
        # SUN397 å¯èƒ½çš„è·¯å¾„ç»“æ„
        possible_paths = [
            os.path.join(data_path, "test"),
            os.path.join(data_path, "sun397"),
            os.path.join(data_path, "images"),
            data_path
        ]
        
        image_folder_path = None
        for path in possible_paths:
            if os.path.exists(path):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å­ç›®å½•
                subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
                if subdirs:
                    image_folder_path = path
                    break
        
        if image_folder_path is None:
            raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° SUN397 çš„å›¾åƒæ–‡ä»¶å¤¹")
        
        print(f"ğŸ” æ‰«æ SUN397 å›¾åƒæ–‡ä»¶å¤¹: {image_folder_path}")
        
        # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        classes = []
        for item in os.listdir(image_folder_path):
            item_path = os.path.join(image_folder_path, item)
            if os.path.isdir(item_path):
                classes.append(item)
        
        classes.sort()
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"ğŸ“ æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes[:5]}{'...' if len(classes) > 5 else ''}")
        
        # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
        for class_name in classes:
            class_dir = os.path.join(image_folder_path, class_name)
            class_idx = self.class_to_idx[class_name]
            
            img_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
            
            for img_name in img_files:
                img_path = os.path.join(class_dir, img_name)
                self.samples.append((img_path, class_idx))
        
        print(f"ğŸ–¼ï¸  æ‰¾åˆ° {len(self.samples)} ä¸ªå›¾åƒæ–‡ä»¶")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        img = Image.open(img_path).convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        return img, label


class FGVCAircraftDataset(Dataset):
    """FGVC Aircraft æ•°æ®é›†åŠ è½½å™¨"""
    def __init__(self, data_path: str, transform=None):
        self.transform = transform
        self.samples = []
        self.class_names = []
        
        # FGVC Aircraftæ•°æ®é›†ç»“æ„
        # data/fgvc_aircraft/fgvc-aircraft-2013b/data/images_variant_test.txt
        # data/fgvc_aircraft/fgvc-aircraft-2013b/data/images/
        
        # æŸ¥æ‰¾æ•°æ®é›†ç›®å½•
        dataset_dir = None
        for item in os.listdir(data_path):
            item_path = os.path.join(data_path, item)
            if os.path.isdir(item_path) and "fgvc-aircraft" in item.lower():
                dataset_dir = item_path
                break
        
        if dataset_dir is None:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°FGVC Aircraftæ•°æ®é›†ç›®å½•åœ¨ {data_path}")
        
        # åŠ è½½ç±»åˆ«åç§°
        variants_file = os.path.join(dataset_dir, "data", "variants.txt")
        if os.path.exists(variants_file):
            with open(variants_file, 'r') as f:
                self.class_names = [line.strip() for line in f.readlines()]
            print(f"âœ… ä» {variants_file} åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
        
        # åŠ è½½æµ‹è¯•é›†æ ‡ç­¾
        test_file = os.path.join(dataset_dir, "data", "images_variant_test.txt")
        if not os.path.exists(test_file):
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æµ‹è¯•é›†æ ‡ç­¾æ–‡ä»¶: {test_file}")
        
        # è¯»å–æµ‹è¯•é›†æ ‡ç­¾
        with open(test_file, 'r') as f:
            lines = f.readlines()
        
        # è§£ææ¯è¡Œï¼šå›¾åƒID ç±»åˆ«åç§°
        for line in lines:
            parts = line.strip().split()
            if len(parts) >= 2:
                image_id = parts[0]
                variant = " ".join(parts[1:])  # å¤„ç†ç±»åˆ«åç§°ä¸­å¯èƒ½åŒ…å«ç©ºæ ¼çš„æƒ…å†µ
                
                # æŸ¥æ‰¾ç±»åˆ«ç´¢å¼•
                if variant in self.class_names:
                    class_idx = self.class_names.index(variant)
                    
                    # æ„å»ºå›¾åƒè·¯å¾„
                    image_path = os.path.join(dataset_dir, "data", "images", f"{image_id}.jpg")
                    
                    if os.path.exists(image_path):
                        self.samples.append((image_path, class_idx))
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªæ ·æœ¬")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        image_path, label = self.samples[idx]
        
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert("RGB")
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    @property
    def class_to_idx(self):
        """ä¸ºäº†å…¼å®¹æ€§ï¼Œæä¾›class_to_idxå±æ€§"""
        return {name: i for i, name in enumerate(self.class_names)}


def load_dataset(dataset_name: str, data_root: str, limit: int = None) -> Tuple[Any, List[str]]:
    """ä»æœ¬åœ° data æ–‡ä»¶å¤¹åŠ è½½æ•°æ®é›†"""
    # æ ‡å‡†å›¾åƒé¢„å¤„ç†
    # CLIP ViT-L/14æ¨¡å‹æœŸæœ›è¾“å…¥å›¾åƒä¸º224x224ï¼Œè¿™æ˜¯å®ƒåœ¨é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„å°ºå¯¸
    # å¤§å¤šæ•°æ•°æ®é›†éœ€è¦resizeåˆ°è¿™ä¸ªå°ºå¯¸ä»¥åŒ¹é…æ¨¡å‹çš„æœŸæœ›è¾“å…¥
    # æ³¨æ„ï¼šMNISTä½¿ç”¨å•ç‹¬çš„transformå¤„ç†ï¼Œå› ä¸ºå®ƒéœ€è¦ç‰¹æ®Šçš„resizeæ“ä½œ
    standard_transform = transforms.Compose([
        transforms.Lambda(lambda img: img.convert("RGB")),
        transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize((0.48145466, 0.4578275, 0.40821073),
                           (0.26862954, 0.26130258, 0.27577711))
    ])
    
    dataset_path = os.path.join(data_root, dataset_name)
    
    try:
        if dataset_name == "imagenet1k":
            # ImageNet1kæ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class ImageNet1kDataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    # åŠ è½½meta.matæ–‡ä»¶è·å–ç±»åˆ«ä¿¡æ¯
                    meta_path = os.path.join(data_path, "ILSVRC2012_devkit_t12", "data", "meta.mat")
                    if not os.path.exists(meta_path):
                        raise FileNotFoundError(f"ImageNet1k metaæ–‡ä»¶ä¸å­˜åœ¨: {meta_path}")
                    
                    import scipy.io
                    meta = scipy.io.loadmat(meta_path)
                    synsets = meta['synsets']
                    
                    # è·å–æ‰€æœ‰ç±»åˆ«ä¿¡æ¯
                    for i in range(synsets.shape[0]):
                        synset = synsets[i][0]
                        # è·å–WNIDå’Œç±»åˆ«åç§°
                        wnid = str(synset[1][0])
                        class_name = str(synset[2][0])
                        self.class_names.append(class_name)
                    
                    # åŠ è½½éªŒè¯é›†æ ‡ç­¾
                    gt_path = os.path.join(data_path, "ILSVRC2012_devkit_t12", "data", "ILSVRC2012_validation_ground_truth.txt")
                    if not os.path.exists(gt_path):
                        raise FileNotFoundError(f"ImageNet1kéªŒè¯é›†æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {gt_path}")
                    
                    with open(gt_path, 'r') as f:
                        labels = [int(line.strip()) for line in f.readlines()]
                    
                    # è·å–æ‰€æœ‰éªŒè¯å›¾åƒ
                    img_files = [f for f in os.listdir(data_path) if f.startswith("ILSVRC2012_val_") and f.endswith(".JPEG")]
                    img_files.sort()
                    
                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for i, img_file in enumerate(img_files):
                        if i < len(labels):
                            label_idx = labels[i] - 1  # MATLABç´¢å¼•ä»1å¼€å§‹ï¼Œè½¬æ¢ä¸º0å¼€å§‹
                            if 0 <= label_idx < len(self.class_names):
                                img_path = os.path.join(data_path, img_file)
                                self.samples.append((img_path, label_idx))
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªImageNet1kéªŒè¯æ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = ImageNet1kDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "cifar10":
            dataset = CIFAR10Dataset(dataset_path, train=False, transform=standard_transform)
            # ä½¿ç”¨å®é™…çš„CIFAR-10ç±»åˆ«åç§°
            class_names = ["airplane", "automobile", "bird", "cat", "deer", "dog", "frog", "horse", "ship", "truck"]
            
        elif dataset_name == "cifar100":
            dataset = CIFAR100Dataset(dataset_path, train=False, transform=standard_transform)
            # ä»CIFAR-100å…ƒæ•°æ®æ–‡ä»¶åŠ è½½å®é™…çš„ç±»åˆ«åç§°
            cifar_path = os.path.join(dataset_path, "cifar-100-python")
            meta_file = os.path.join(cifar_path, "meta")
            
            try:
                with open(meta_file, 'rb') as f:
                    meta = pickle.load(f, encoding='bytes')
                    # è·å–ç»†ç²’åº¦ç±»åˆ«åç§°
                    class_names = [label.decode('utf-8') for label in meta[b'fine_label_names']]
                    print(f"âœ… ä»å…ƒæ•°æ®æ–‡ä»¶åŠ è½½äº† {len(class_names)} ä¸ªCIFAR-100ç±»åˆ«")
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åŠ è½½CIFAR-100å…ƒæ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«åç§°: {e}")
                # ä½¿ç”¨é»˜è®¤çš„CIFAR-100ç±»åˆ«åç§°
                class_names = [
                    "apple", "aquarium_fish", "baby", "bear", "beaver", "bed", "bee", "beetle",
                    "bicycle", "bottle", "bowl", "boy", "bridge", "bus", "butterfly", "camel",
                    "can", "castle", "caterpillar", "cattle", "chair", "chimpanzee", "clock",
                    "cloud", "cockroach", "couch", "crab", "crocodile", "cruise_ship", "cup",
                    "dinosaur", "dolphin", "elephant", "flatfish", "forest", "fox", "girl", "hamster",
                    "house", "kangaroo", "computer_keyboard", "lamp", "lawn_mower", "leopard", "lion",
                    "lizard", "lobster", "man", "maple_tree", "motorcycle", "mountain", "mouse",
                    "mushroom", "oak_tree", "orange", "orchid", "otter", "palm_tree", "pear",
                    "pickup_truck", "pine_tree", "plain", "plate", "poppy", "porcupine", "possum",
                    "rabbit", "raccoon", "ray", "road", "rocket", "rose", "sea", "seal", "shark",
                    "shrew", "skunk", "skyscraper", "snail", "snake", "spider", "squirrel", "streetcar",
                    "sunflower", "sweet_pepper", "table", "tank", "telephone", "television", "tiger",
                    "tractor", "train", "trout", "tulip", "turtle", "wardrobe", "whale", "willow_tree",
                    "wolf", "woman", "worm", "zookeeper"
                ]
            
        elif dataset_name == "mnist":
            # MNISTéœ€è¦ç‰¹æ®Šçš„resizeå¤„ç†ï¼Œå› ä¸ºåŸå§‹å›¾åƒå¾ˆå°(28x28)
            mnist_transform = transforms.Compose([
                transforms.Lambda(lambda img: img.convert("RGB")),
                transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize((0.48145466, 0.4578275, 0.40821073),
                                   (0.26862954, 0.26130258, 0.27577711))
            ])
            try:
                dataset = tv_datasets.MNIST(
                    root=dataset_path,
                    train=False,
                    transform=mnist_transform,
                    download=False,
                )
            except RuntimeError as exc:
                raw_candidates = [
                    os.path.join(dataset_path, "MNIST", "raw"),
                    os.path.join(dataset_path, "raw"),
                ]
                for raw_root in raw_candidates:
                    if os.path.exists(raw_root):
                        dataset = MNISTRawFallbackDataset(raw_root, split="test", transform=mnist_transform)
                        break
                else:
                    raise RuntimeError(
                        "æœªæ‰¾åˆ°å¤„ç†åçš„ MNIST æ–‡ä»¶ï¼Œä¸”åŸå§‹æ•°æ®ç¼ºå¤±ã€‚è¯·å…ˆä¸‹è½½ MNIST æ•°æ®é›†ã€‚"
                    ) from exc
            class_names = DATASET_CLASSES["mnist"]
            
        elif dataset_name == "caltech101":
            dataset = Caltech101Dataset(dataset_path, transform=standard_transform)
            class_names = list(dataset.class_to_idx.keys())
            
        elif dataset_name == "stanford_cars":
            dataset = StanfordCarsDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.class_names
            
        elif dataset_name == "flowers102":
            dataset = Flowers102Dataset(dataset_path, transform=standard_transform)
            class_names = dataset.get_classes()
            
        elif dataset_name == "food101":
            dataset = Food101Dataset(dataset_path, transform=standard_transform)
            class_names = dataset.get_classes()
            
        elif dataset_name == "pets":
            dataset = PetsDataset(dataset_path, transform=standard_transform)
            class_names = dataset.class_names
            
        elif dataset_name == "dtd":
            # DTDæ•°æ®é›†çš„å›¾åƒåœ¨dtdå­ç›®å½•çš„imagesæ–‡ä»¶å¤¹ä¸­
            dtd_path = os.path.join(dataset_path, "dtd", "images")
            dataset = DTDataset(dtd_path, transform=standard_transform)
            class_names = list(dataset.class_to_idx.keys())
            
        elif dataset_name == "gtsrb":
            # GTSRBæ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå›¾åƒå’Œæ ‡ç­¾åœ¨ä¸åŒçš„ä½ç½®
            class GTSRBDataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    
                    # GTSRBç±»åˆ«åç§°
                    self.class_names = [
                        "Speed limit (20km/h)", "Speed limit (30km/h)", "Speed limit (50km/h)", "Speed limit (60km/h)",
                        "Speed limit (70km/h)", "Speed limit (80km/h)", "End of speed limit (80km/h)", "Speed limit (100km/h)",
                        "Speed limit (120km/h)", "No passing", "No passing for vehicles over 3.5 metric tons",
                        "Right-of-way at the next intersection", "Priority road", "Yield", "Stop",
                        "No vehicles", "Vehicles over 3.5 metric tons prohibited", "No entry", "General caution",
                        "Dangerous curve to the left", "Dangerous curve to the right", "Double curve", "Bumpy road",
                        "Slippery road", "Road narrows on the right", "Road work", "Traffic signals",
                        "Pedestrians", "Children crossing", "Bicycles crossing", "Beware of ice/snow",
                        "Wild animals crossing", "End of all speed and passing limits", "Turn right ahead", "Turn left ahead",
                        "Ahead only", "Go straight or right", "Go straight or left", "Keep right",
                        "Keep left", "Roundabout mandatory", "End of no passing", "End of no passing by vehicles over 3.5 metric tons"
                    ]
                    
                    # å›¾åƒè·¯å¾„
                    images_path = os.path.join(data_path, "gtsrb", "GTSRB", "Final_Test", "Images")
                    # æ ‡ç­¾æ–‡ä»¶è·¯å¾„
                    labels_path = os.path.join(data_path, "gtsrb", "GT-final_test.csv")
                    
                    # è¯»å–æ ‡ç­¾æ–‡ä»¶
                    import pandas as pd
                    df = pd.read_csv(labels_path, sep=';')
                    
                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for idx, row in df.iterrows():
                        if limit is not None and len(self.samples) >= limit:
                            break
                        
                        filename = row['Filename']
                        class_id = int(row['ClassId'])
                        
                        # ç¡®ä¿ç±»åˆ«IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if class_id < len(self.class_names):
                            img_path = os.path.join(images_path, filename)
                            if os.path.exists(img_path):
                                self.samples.append((img_path, class_id))
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = GTSRBDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "stl10":
            # STL10æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä½¿ç”¨äºŒè¿›åˆ¶æ–‡ä»¶
            class STL10Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    
                    # STL10ç±»åˆ«åç§°
                    class_names_file = os.path.join(data_path, "stl10_binary", "class_names.txt")
                    with open(class_names_file, 'r') as f:
                        self.class_names = [line.strip() for line in f.readlines()]
                    
                    # è¯»å–äºŒè¿›åˆ¶æ•°æ®æ–‡ä»¶
                    test_x_file = os.path.join(data_path, "stl10_binary", "test_X.bin")
                    test_y_file = os.path.join(data_path, "stl10_binary", "test_y.bin")
                    
                    # è¯»å–å›¾åƒæ•°æ®
                    with open(test_x_file, 'rb') as f:
                        # STL10å›¾åƒæ˜¯96x96x3çš„RGBå›¾åƒ
                        # æ¯ä¸ªå›¾åƒæœ‰96*96*3 = 27648å­—èŠ‚
                        raw_data = f.read()
                        num_images = len(raw_data) // (96 * 96 * 3)
                        
                        # å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºå›¾åƒæ•°ç»„
                        import numpy as np
                        images = np.frombuffer(raw_data, dtype=np.uint8)
                        images = images.reshape(num_images, 3, 96, 96)  # é€šé“ä¼˜å…ˆ
                        images = images.transpose(0, 2, 3, 1)  # è½¬æ¢ä¸ºå›¾åƒä¼˜å…ˆ
                    
                    # è¯»å–æ ‡ç­¾
                    with open(test_y_file, 'rb') as f:
                        labels = np.frombuffer(f.read(), dtype=np.uint8)
                    
                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for i in range(min(num_images, len(labels))):
                        if limit is not None and len(self.samples) >= limit:
                            break
                        
                        # STL-10æ ‡ç­¾ä»1å¼€å§‹ï¼Œéœ€è¦è½¬æ¢ä¸º0å¼€å§‹çš„ç´¢å¼•
                        label_idx = int(labels[i] - 1)  # ç¡®ä¿è½¬æ¢ä¸ºPython intç±»å‹
                        if 0 <= label_idx < len(self.class_names):
                            self.samples.append((images[i], label_idx))
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    image_array, label = self.samples[idx]
                    
                    # ä»numpyæ•°ç»„åˆ›å»ºå›¾åƒ
                    img = Image.fromarray(image_array, mode='RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = STL10Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "sun397":
            dataset = SUN397Dataset(dataset_path, transform=standard_transform)
            class_names = list(dataset.class_to_idx.keys())
            
        elif dataset_name == "fer2013":
            # FER2013 æ•°æ®é›†åŠ è½½å™¨
            class FER2013Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = ["angry", "disgust", "fear", "happy", "sad", "surprise", "neutral"]
                    
                    # åŠ è½½CSVæ–‡ä»¶
                    csv_path = os.path.join(data_path, "fer2013.csv")
                    if not os.path.exists(csv_path):
                        raise FileNotFoundError(f"FER2013 CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
                    
                    import pandas as pd
                    df = pd.read_csv(csv_path)
                    
                    # åªä½¿ç”¨æµ‹è¯•é›†
                    df = df[df['Usage'] == 'PublicTest']
                    
                    # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
                    for idx, row in df.iterrows():
                        if limit is not None and len(self.samples) >= limit:
                            break
                        
                        emotion = int(row['emotion'])
                        pixels = row['pixels']
                        
                        # å°†åƒç´ å­—ç¬¦ä¸²è½¬æ¢ä¸ºnumpyæ•°ç»„
                        pixel_array = np.array([int(p) for p in pixels.split()]).reshape(48, 48)
                        
                        # ç¡®ä¿emotionåœ¨æœ‰æ•ˆèŒƒå›´å†…
                        emotion = min(emotion, len(self.class_names) - 1)
                        
                        self.samples.append((pixel_array, emotion))
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    pixel_array, label = self.samples[idx]
                    
                    # ä»åƒç´ æ•°ç»„åˆ›å»ºå›¾åƒ
                    img = Image.fromarray(pixel_array.astype(np.uint8), mode='L').convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
            
            dataset = FER2013Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.class_names
            
        elif dataset_name == "fgvc_aircraft":
            dataset = FGVCAircraftDataset(dataset_path, transform=standard_transform)
            class_names = dataset.class_names
            
        elif dataset_name == "resisc45":
            # Resisc45æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä½¿ç”¨Parquetæ–‡ä»¶
            class Resisc45Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    
                    # Resisc45ç±»åˆ«åç§°
                    self.class_names = [
                        "airplane", "airport", "baseball_diamond", "basketball_court", "beach",
                        "bridge", "chaparral", "church", "circular_farmland", "cloud",
                        "commercial_area", "dense_residential", "desert", "forest", "freeway",
                        "golf_course", "ground_track_field", "harbor", "industrial_area", "intersection",
                        "island", "lake", "meadow", "medium_residential", "mobile_home_park",
                        "mountain", "overpass", "palace", "parking_lot", "railway",
                        "railway_station", "rectangular_farmland", "river", "roundabout", "runway",
                        "sea_ice", "ship", "snowberg", "sparse_residential", "stadium",
                        "storage_tank", "tennis_court", "terrace", "thermal_power_station", "wetland"
                    ]
                    
                    # æµ‹è¯•é›†Parquetæ–‡ä»¶è·¯å¾„
                    test_file = os.path.join(data_path, "data", "test-00000-of-00001.parquet")
                    
                    if not os.path.exists(test_file):
                        raise FileNotFoundError(f"Resisc45æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
                    
                    # è¯»å–Parquetæ–‡ä»¶
                    import pandas as pd
                    df = pd.read_parquet(test_file)
                    
                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for idx, row in df.iterrows():
                        if limit is not None and len(self.samples) >= limit:
                            break
                        
                        image = row['image']
                        label = int(row['label'])
                        
                        # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if 0 <= label < len(self.class_names):
                            self.samples.append((image, label))
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    image_data, label = self.samples[idx]
                    
                    # å¤„ç†å­—å…¸æ ¼å¼çš„å›¾åƒæ•°æ®
                    if isinstance(image_data, dict):
                        # ä»å­—å…¸ä¸­æå–å›¾åƒæ•°æ®
                        if 'bytes' in image_data:
                            # ä»å­—èŠ‚æ•°æ®åˆ›å»ºå›¾åƒ
                            from io import BytesIO
                            image = Image.open(BytesIO(image_data['bytes']))
                        elif 'path' in image_data:
                            # ä»è·¯å¾„åŠ è½½å›¾åƒ
                            image = Image.open(image_data['path'])
                        else:
                            raise ValueError(f"æ— æ³•è¯†åˆ«çš„å›¾åƒæ•°æ®æ ¼å¼: {image_data.keys()}")
                    else:
                        # ç¡®ä¿å›¾åƒæ˜¯PIL Image
                        if not isinstance(image_data, Image.Image):
                            image = Image.fromarray(image_data)
                        else:
                            image = image_data
                    
                    # è½¬æ¢ä¸ºRGB
                    if image.mode != 'RGB':
                        image = image.convert('RGB')
                    
                    if self.transform:
                        image = self.transform(image)
                    
                    return image, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = Resisc45Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "imagenet_v2":
            # ImageNet V2æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class ImageNetV2Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    # ImageNet V2æ•°æ®é›†è·¯å¾„
                    v2_path = os.path.join(data_path, "imagenetv2-matched-frequency-format-val")
                    if not os.path.exists(v2_path):
                        raise FileNotFoundError(f"ImageNet V2æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {v2_path}")
                    
                    # è·å–æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
                    class_dirs = [d for d in os.listdir(v2_path)
                                 if os.path.isdir(os.path.join(v2_path, d))]
                    class_dirs.sort(key=int)  # æŒ‰æ•°å­—æ’åº
                    
                    # åˆ›å»ºç±»åˆ«åç§°åˆ—è¡¨ï¼Œä½¿ç”¨ç®€å•çš„ç¼–å·
                    num_classes = len(class_dirs)
                    self.class_names = [f"imagenet_v2_class_{i}" for i in range(num_classes)]
                    
                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for class_dir in class_dirs:
                        # ImageNet V2çš„ç±»åˆ«æ–‡ä»¶å¤¹åç§°æ˜¯æ•°å­—ï¼Œç›´æ¥ä½œä¸ºç´¢å¼•
                        class_idx = int(class_dir)  # å·²ç»æ˜¯0å¼€å§‹çš„ç´¢å¼•
                        if class_idx < 0 or class_idx >= len(self.class_names):
                            continue  # è·³è¿‡è¶…å‡ºèŒƒå›´çš„ç±»åˆ«
                        
                        class_path = os.path.join(v2_path, class_dir)
                        img_files = [f for f in os.listdir(class_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        
                        for img_file in img_files:
                            img_path = os.path.join(class_path, img_file)
                            self.samples.append((img_path, class_idx))
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªImageNet V2æ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = ImageNetV2Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "imagenet_ske":
            # ImageNet Sketchæ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class ImageNetSkeDataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    # å°è¯•åŠ è½½ç±»åˆ«ä¿¡æ¯
                    classes_file = os.path.join(data_path, "classes.py")
                    if os.path.exists(classes_file):
                        # æ‰§è¡Œclasses.pyæ–‡ä»¶ä»¥è·å–ç±»åˆ«ä¿¡æ¯
                        import sys
                        sys.path.append(os.path.dirname(classes_file))
                        import classes as imagenet_classes
                        self.class_names = list(imagenet_classes.IMAGENET2012_CLASSES.values())
                        # åˆ›å»ºä¸€ä¸ªä»WNIDåˆ°ç´¢å¼•çš„æ˜ å°„
                        wnid_to_idx = {wnid: i for i, wnid in enumerate(imagenet_classes.IMAGENET2012_CLASSES.keys())}
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°classes.pyï¼Œå°è¯•ä½¿ç”¨ImageNet1kçš„metaæ–‡ä»¶
                        meta_path = os.path.join(data_root, "imagenet1k", "ILSVRC2012_devkit_t12", "data", "meta.mat")
                        if os.path.exists(meta_path):
                            import scipy.io
                            meta = scipy.io.loadmat(meta_path)
                            synsets = meta['synsets']
                            
                            # è·å–æ‰€æœ‰ç±»åˆ«ä¿¡æ¯
                            for i in range(synsets.shape[0]):
                                synset = synsets[i][0]
                                # è·å–WNIDå’Œç±»åˆ«åç§°
                                wnid = str(synset[1][0])
                                class_name = str(synset[2][0])
                                self.class_names.append(class_name)
                            
                            # åˆ›å»ºä¸€ä¸ªä»WNIDåˆ°ç´¢å¼•çš„æ˜ å°„
                            wnid_to_idx = {}
                            for i in range(synsets.shape[0]):
                                synset = synsets[i][0]
                                wnid = str(synset[1][0])
                                wnid_to_idx[wnid] = i
                        else:
                            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ç®€åŒ–çš„ç±»åˆ«åç§°
                            self.class_names = [f"imagenet_class_{i}" for i in range(1000)]
                            wnid_to_idx = {f"n{i:08d}": i for i in range(1000)}

                    sketch_path = os.path.join(data_path, "imagenet-sketch")
                    if not os.path.isdir(sketch_path):
                        alt_path = os.path.join(data_path, "data", "sketch")
                        if os.path.isdir(alt_path):
                            sketch_path = alt_path
                        else:
                            raise FileNotFoundError(f"ImageNet Sketchæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {sketch_path}")

                    class_dirs = [d for d in os.listdir(sketch_path)
                                  if os.path.isdir(os.path.join(sketch_path, d))]
                    class_dirs.sort()

                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for class_dir in class_dirs:
                        if class_dir not in wnid_to_idx:
                            continue  # è·³è¿‡ä¸åœ¨ç±»åˆ«åˆ—è¡¨ä¸­çš„æ–‡ä»¶å¤¹
                        
                        class_idx = wnid_to_idx[class_dir]
                        class_path = os.path.join(sketch_path, class_dir)
                        img_files = [f for f in os.listdir(class_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        
                        for img_file in img_files:
                            img_path = os.path.join(class_path, img_file)
                            self.samples.append((img_path, class_idx))
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªImageNet Sketchæ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = ImageNetSkeDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "imagenet_ren":
            # ImageNet Renditionsæ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class ImageNetRenDataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    # è§£æImageNet1kçš„ç±»åˆ«å…ƒæ•°æ®ï¼Œæ„å»ºWNIDåˆ°å¯è¯»åç§°çš„æ˜ å°„
                    meta_path = os.path.join(data_root, "imagenet1k", "ILSVRC2012_devkit_t12", "data", "meta.mat")
                    wnid_to_name: Dict[str, str] = {}
                    if os.path.exists(meta_path):
                        import scipy.io
                        meta = scipy.io.loadmat(meta_path)
                        synsets = meta["synsets"]
                        for i in range(synsets.shape[0]):
                            synset = synsets[i][0]
                            wnid = str(synset[1][0])
                            class_name = str(synset[2][0])
                            wnid_to_name[wnid] = class_name

                    ren_path = os.path.join(data_path, "imagenet-r")
                    if not os.path.isdir(ren_path):
                        alt_path = os.path.join(data_path, "data", "imagenet-r")
                        if os.path.isdir(alt_path):
                            ren_path = alt_path
                        else:
                            raise FileNotFoundError(f"ImageNet Renditionsæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {ren_path}")

                    class_dirs = [d for d in os.listdir(ren_path)
                                  if os.path.isdir(os.path.join(ren_path, d))]
                    class_dirs.sort()

                    wnid_to_idx = {}
                    self.class_names = []
                    for idx, class_dir in enumerate(class_dirs):
                        wnid_to_idx[class_dir] = idx
                        self.class_names.append(wnid_to_name.get(class_dir, class_dir))

                    # åˆ›å»ºæ ·æœ¬åˆ—è¡¨
                    for class_dir in class_dirs:
                        class_idx = wnid_to_idx[class_dir]
                        class_path = os.path.join(ren_path, class_dir)
                        img_files = [f for f in os.listdir(class_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        
                        for img_file in img_files:
                            img_path = os.path.join(class_path, img_file)
                            self.samples.append((img_path, class_idx))
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªImageNet Renditionsæ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = ImageNetRenDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "imagenet_adv":
            # ImageNet-A (Adversarial)æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class ImageNetAdvDataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    label_to_idx: Dict[str, int] = {}
                    unique_labels: List[str] = []

                    # è¯»å–samples.jsonæ–‡ä»¶
                    samples_file = os.path.join(data_path, "samples.json")
                    if not os.path.exists(samples_file):
                        raise FileNotFoundError(f"ImageNet-A samples.jsonæ–‡ä»¶ä¸å­˜åœ¨: {samples_file}")
                    
                    import json
                    with open(samples_file, 'r') as f:
                        data = json.load(f)
                        samples = data.get('samples', [])
                        
                        # å¤„ç†æ¯ä¸ªæ ·æœ¬
                        for sample in samples:
                            # è·å–å›¾åƒè·¯å¾„
                            filepath = sample.get('filepath', '')
                            if not filepath:
                                continue
                                
                            # è·å–çœŸå®æ ‡ç­¾
                            ground_truth = sample.get('ground_truth', {})
                            label_str = ground_truth.get('label', '')
                            label_clean = label_str.strip()
                            if not label_clean:
                                continue

                            normalized_label = label_clean.lower()
                            class_idx = label_to_idx.get(normalized_label)
                            if class_idx is None:
                                class_idx = len(unique_labels)
                                label_to_idx[normalized_label] = class_idx
                                unique_labels.append(label_clean)

                            # æ„å»ºå®Œæ•´çš„å›¾åƒè·¯å¾„
                            img_path = os.path.join(data_path, filepath)
                            if os.path.exists(img_path):
                                self.samples.append((img_path, class_idx))
                    
                    self.class_names = unique_labels
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªImageNet-Aæ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = ImageNetAdvDataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "voc2007":
            # PASCAL VOC 2007æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œä½¿ç”¨Parquetæ ¼å¼
            class VOC2007Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = [
                        "aeroplane", "bicycle", "bird", "boat", "bottle",
                        "bus", "car", "cat", "chair", "cow",
                        "diningtable", "dog", "horse", "motorbike", "person",
                        "pottedplant", "sheep", "sofa", "train", "tvmonitor"
                    ]
                    
                    # VOC2007æ•°æ®é›†è·¯å¾„
                    parquet_file = os.path.join(data_path, "data", "train-00000-of-00001.parquet")
                    if not os.path.exists(parquet_file):
                        raise FileNotFoundError(f"PASCAL VOC 2007 Parquetæ–‡ä»¶ä¸å­˜åœ¨: {parquet_file}")
                    
                    print(f"ğŸ”„ ä»Parquetæ–‡ä»¶åŠ è½½PASCAL VOC 2007æ•°æ®é›†: {parquet_file}")
                    
                    # è¯»å–Parquetæ–‡ä»¶
                    import pandas as pd
                    df = pd.read_parquet(parquet_file)
                    
                    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(df)}")
                    print(f"ğŸ“‹ æ•°æ®é›†åˆ—: {list(df.columns)}")
                    
                    # å¤„ç†æ¯ä¸ªæ ·æœ¬
                    for idx, row in df.iterrows():
                        if limit is not None and len(self.samples) >= limit:
                            break
                        
                        try:
                            # è·å–å›¾åƒæ•°æ®
                            image_data = row.get('image')
                            if image_data is None:
                                continue
                            
                            # è·å–æ ‡ç­¾
                            label = row.get('label')
                            if label is None:
                                continue
                            
                            # ç¡®ä¿æ ‡ç­¾åœ¨æœ‰æ•ˆèŒƒå›´å†…
                            if isinstance(label, (int, np.integer)) and 0 <= label < len(self.class_names):
                                self.samples.append((image_data, int(label)))
                            elif isinstance(label, str) and label in self.class_names:
                                class_idx = self.class_names.index(label)
                                self.samples.append((image_data, class_idx))
                            else:
                                # å°è¯•å°†æ ‡ç­¾è½¬æ¢ä¸ºæ•´æ•°
                                try:
                                    label_int = int(label)
                                    if 0 <= label_int < len(self.class_names):
                                        self.samples.append((image_data, label_int))
                                except (ValueError, TypeError):
                                    print(f"âš ï¸  æ— æ³•å¤„ç†çš„æ ‡ç­¾: {label} (ç±»å‹: {type(label)})")
                                    continue
                        except Exception as e:
                            print(f"âš ï¸  å¤„ç†æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}")
                            continue
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªPASCAL VOC 2007æ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    image_data, label = self.samples[idx]
                    
                    # å¤„ç†ä¸åŒç±»å‹çš„å›¾åƒæ•°æ®
                    if isinstance(image_data, dict):
                        # ä»å­—å…¸ä¸­æå–å›¾åƒæ•°æ®
                        if 'bytes' in image_data:
                            # ä»å­—èŠ‚æ•°æ®åˆ›å»ºå›¾åƒ
                            from io import BytesIO
                            image = Image.open(BytesIO(image_data['bytes']))
                        elif 'path' in image_data:
                            # ä»è·¯å¾„åŠ è½½å›¾åƒ
                            image = Image.open(image_data['path'])
                        else:
                            raise ValueError(f"æ— æ³•è¯†åˆ«çš„å›¾åƒæ•°æ®æ ¼å¼: {image_data.keys()}")
                    else:
                        # ç¡®ä¿å›¾åƒæ˜¯PIL Image
                        if not isinstance(image_data, Image.Image):
                            image = Image.fromarray(image_data)
                        else:
                            image = image_data
                    
                    # è½¬æ¢ä¸ºRGB
                    if image.mode != 'RGB':
                        image = image.convert('RGB')
                    
                    if self.transform:
                        image = self.transform(image)
                    
                    return image, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = VOC2007Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "rendered_sst2":
            # Rendered SST2æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class RenderedSST2Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = ["negative", "positive"]
                    
                    # Rendered SST2æ•°æ®é›†è·¯å¾„
                    rendered_sst2_path = os.path.join(data_path, "rendered-sst2")
                    if not os.path.exists(rendered_sst2_path):
                        alt_path = os.path.join(data_path, "Rendered-SST2")
                        if os.path.exists(alt_path):
                            rendered_sst2_path = alt_path
                        elif os.path.exists(os.path.join(data_path, "test")):
                            rendered_sst2_path = data_path
                        else:
                            raise FileNotFoundError(f"Rendered SST2æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {rendered_sst2_path}")
                    
                    # æµ‹è¯•é›†è·¯å¾„
                    test_path = os.path.join(rendered_sst2_path, "test")
                    if not os.path.exists(test_path):
                        raise FileNotFoundError(f"Rendered SST2æµ‹è¯•é›†è·¯å¾„ä¸å­˜åœ¨: {test_path}")
                    
                    # å¤„ç†negativeç±»åˆ«
                    negative_path = os.path.join(test_path, "negative")
                    if os.path.exists(negative_path):
                        img_files = [f for f in os.listdir(negative_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        for img_file in img_files:
                            img_path = os.path.join(negative_path, img_file)
                            self.samples.append((img_path, 0))  # negativeçš„æ ‡ç­¾ä¸º0
                    
                    # å¤„ç†positiveç±»åˆ«
                    positive_path = os.path.join(test_path, "positive")
                    if os.path.exists(positive_path):
                        img_files = [f for f in os.listdir(positive_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        for img_file in img_files:
                            img_path = os.path.join(positive_path, img_file)
                            self.samples.append((img_path, 1))  # positiveçš„æ ‡ç­¾ä¸º1
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªRendered SST2æ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªç±»åˆ«")
                    
                    if limit is not None:
                        print(f"âš ï¸  limit å‚æ•°åœ¨ Rendered SST2 ä¸­ä»…ç”¨äºæ—¥å¿—ï¼Œå®é™…æˆªæ–­å°†ç”±è¯„ä¼°é˜¶æ®µå¤„ç†ã€‚")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = RenderedSST2Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        elif dataset_name == "country211":
            # Country-211æ•°æ®é›†éœ€è¦ç‰¹æ®Šå¤„ç†
            class Country211Dataset(Dataset):
                def __init__(self, data_path: str, transform=None, limit=None):
                    self.transform = transform
                    self.samples = []
                    self.class_names = []
                    
                    # Country-211æ•°æ®é›†è·¯å¾„
                    country211_path = os.path.join(data_path, "country211", "test")
                    if not os.path.exists(country211_path):
                        raise FileNotFoundError(f"Country-211æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {country211_path}")
                    
                    print(f"ğŸ” æ‰«æ Country-211 æ•°æ®é›†: {country211_path}")
                    
                    # è·å–æ‰€æœ‰å›½å®¶ä»£ç ç›®å½•
                    country_dirs = [d for d in os.listdir(country211_path)
                                  if os.path.isdir(os.path.join(country211_path, d))]
                    country_dirs.sort()
                    
                    # åˆ›å»ºå›½å®¶ä»£ç åˆ°å›½å®¶åç§°çš„æ˜ å°„
                    # è¿™é‡Œä½¿ç”¨å›½å®¶ä»£ç ä½œä¸ºç±»åˆ«åç§°ï¼Œå› ä¸ºæ•°æ®é›†æ²¡æœ‰æä¾›å®Œæ•´çš„å›½å®¶åç§°
                    self.class_names = country_dirs
                    
                    # åˆ›å»ºå›½å®¶ä»£ç åˆ°ç´¢å¼•çš„æ˜ å°„
                    country_to_idx = {country: i for i, country in enumerate(country_dirs)}
                    
                    # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
                    for country_code in country_dirs:
                        country_idx = country_to_idx[country_code]
                        country_path = os.path.join(country211_path, country_code)
                        
                        img_files = [f for f in os.listdir(country_path)
                                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
                        
                        for img_file in img_files:
                            img_path = os.path.join(country_path, img_file)
                            self.samples.append((img_path, country_idx))
                    
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(self.samples)} ä¸ªCountry-211æ ·æœ¬")
                    print(f"âœ… åŠ è½½äº† {len(self.class_names)} ä¸ªå›½å®¶/åœ°åŒº")
                    
                    # é™åˆ¶æ ·æœ¬æ•°é‡
                    if limit is not None and limit < len(self.samples):
                        self.samples = self.samples[:limit]
                        print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
                
                def __len__(self):
                    return len(self.samples)
                
                def __getitem__(self, idx):
                    img_path, label = self.samples[idx]
                    
                    # åŠ è½½å›¾åƒ
                    img = Image.open(img_path).convert('RGB')
                    
                    if self.transform:
                        img = self.transform(img)
                    
                    return img, label
                
                def get_classes(self):
                    return self.class_names
            
            dataset = Country211Dataset(dataset_path, transform=standard_transform, limit=limit)
            class_names = dataset.get_classes()
            
        else:
            # å°è¯•ä½œä¸ºé€šç”¨å›¾åƒæ–‡ä»¶å¤¹æ•°æ®é›†åŠ è½½
            if os.path.exists(dataset_path):
                # æ£€æŸ¥æ˜¯å¦æœ‰å­ç›®å½•ç»“æ„ï¼ˆæ¯ä¸ªå­ç›®å½•ä»£è¡¨ä¸€ä¸ªç±»åˆ«ï¼‰
                subdirs = [d for d in os.listdir(dataset_path)
                          if os.path.isdir(os.path.join(dataset_path, d))]
                
                if subdirs:
                    # ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„å›¾åƒæ–‡ä»¶å¤¹æ•°æ®é›†
                    class GenericImageFolderDataset(Dataset):
                        def __init__(self, root_path: str, transform=None):
                            self.transform = transform
                            self.samples = []
                            self.class_to_idx = {}
                            
                            # æŸ¥æ‰¾æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
                            classes = []
                            for item in os.listdir(root_path):
                                item_path = os.path.join(root_path, item)
                                if os.path.isdir(item_path):
                                    classes.append(item)
                            
                            classes.sort()
                            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
                            
                            # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
                            for class_name in classes:
                                class_dir = os.path.join(root_path, class_name)
                                class_idx = self.class_to_idx[class_name]
                                
                                for img_name in os.listdir(class_dir):
                                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
                                        img_path = os.path.join(class_dir, img_name)
                                        self.samples.append((img_path, class_idx))
                        
                        def __len__(self):
                            return len(self.samples)
                        
                        def __getitem__(self, idx):
                            img_path, label = self.samples[idx]
                            
                            # åŠ è½½å›¾åƒ
                            img = Image.open(img_path).convert('RGB')
                            
                            if self.transform:
                                img = self.transform(img)
                            
                            return img, label
                    
                    dataset = GenericImageFolderDataset(dataset_path, transform=standard_transform)
                    class_names = list(dataset.class_to_idx.keys())
                else:
                    raise FileNotFoundError(f"æ•°æ®é›† {dataset_name} æ²¡æœ‰æœ‰æ•ˆçš„å­ç›®å½•ç»“æ„")
            else:
                raise FileNotFoundError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
                
        return dataset, class_names
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›† {dataset_name} å¤±è´¥: {str(e)}")
        print(f"ğŸ“ å°è¯•çš„è·¯å¾„: {dataset_path}")
        raise


def load_clip_model(model_root: str, device: torch.device, dtype: torch.dtype):
    """ä»æœ¬åœ°åŠ è½½ CLIP æ¨¡å‹"""
    try:
        from transformers import CLIPModel, CLIPProcessor
        
        model_path = os.path.join(model_root, "clip")
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"CLIP æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        
        print(f"ğŸ¤– ä» {model_path} åŠ è½½ CLIP æ¨¡å‹...")
        
        model = CLIPModel.from_pretrained(model_path)
        if dtype is not None:
            model = model.to(dtype=dtype)
        model = model.to(device)
        model.eval()
        
        processor = CLIPProcessor.from_pretrained(model_path)
        
        print("âœ… CLIP æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model, processor
        
    except Exception as e:
        print(f"âŒ åŠ è½½ CLIP æ¨¡å‹å¤±è´¥: {str(e)}")
        raise


def create_text_prompts(class_names: List[str], dataset_name: Optional[str] = None) -> List[str]:
    """åˆ›å»ºæ–‡æœ¬æç¤º"""
    prompts = []
    if dataset_name == "mnist":
        for class_name in class_names:
            prompts.append(f"the number {class_name}")
    else:
        for class_name in class_names:
            formatted_name = class_name.replace('_', ' ').strip()
            prompts.append(f"a photo of a {formatted_name}")
    return prompts


def calculate_metrics(
    predictions: torch.Tensor,
    targets: torch.Tensor,
    top_k: int = 5,
    num_classes: int = None
) -> Dict[str, float]:
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    # Top-1 å‡†ç¡®ç‡
    top1_acc = (predictions[:, 0] == targets).float().mean().item()
    
    # Top-k å‡†ç¡®ç‡
    topk_acc = 0.0
    if top_k > 1:
        correct = torch.zeros_like(targets, dtype=torch.bool)
        # ç¡®ä¿kä¸è¶…è¿‡ç±»åˆ«æ•°é‡å’Œé¢„æµ‹ç»´åº¦
        max_k = min(top_k, predictions.size(1), num_classes)
        for k in range(max_k):
            correct |= (predictions[:, k] == targets)
        topk_acc = correct.float().mean().item()
    
    # è®¡ç®—æ··æ·†çŸ©é˜µï¼ˆä»…é€‚ç”¨äºå°æ•°æ®é›†ï¼‰
    if num_classes is None:
        num_classes = max(targets.max().item() + 1, predictions.size(1))
    # ç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
    t = targets.long()
    p = predictions[:, 0].long()
    # é™åˆ¶é¢„æµ‹å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
    p = torch.clamp(p, 0, num_classes - 1)
    t = torch.clamp(t, 0, num_classes - 1)
    
    confusion_matrix = torch.zeros(num_classes, num_classes, dtype=torch.int64)
    for ti, pi in zip(t, p):
        confusion_matrix[ti, pi] += 1
    
    return {
        "top1_accuracy": top1_acc,
        f"top{top_k}_accuracy": topk_acc,
        "confusion_matrix": confusion_matrix.tolist()
    }


def evaluate_dataset(
    model,
    processor,
    dataset_name: str,
    data_root: str,
    batch_size: int,
    num_workers: int,
    device: torch.device,
    limit: int = None,
    top_k: int = 5
) -> Dict[str, Any]:
    """è¯„ä¼°å•ä¸ªæ•°æ®é›†"""
    print(f"\nğŸ”„ å¼€å§‹è¯„ä¼°æ•°æ®é›†: {dataset_name}")
    
    try:
        # åŠ è½½æ•°æ®é›†
        dataset, class_names = load_dataset(dataset_name, data_root, limit)
        
        # é™åˆ¶æ ·æœ¬æ•°é‡
        if limit is not None and limit < len(dataset):
            indices = torch.randperm(len(dataset))[:limit]
            dataset = torch.utils.data.Subset(dataset, indices)
            print(f"âš ï¸  é™åˆ¶æ ·æœ¬æ•°é‡ä¸º: {limit}")
        
        print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {len(dataset)}")
        print(f"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {len(class_names)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=device.type == "cuda"
        )
        
        # ç¼–ç æ–‡æœ¬ç‰¹å¾
        print("ğŸ“ ç¼–ç æ–‡æœ¬ç‰¹å¾...")
        text_prompts = create_text_prompts(class_names, dataset_name=dataset_name)
        with torch.no_grad():
            text_inputs = processor(text=text_prompts, padding=True, return_tensors="pt").to(device)
            text_features = model.get_text_features(**text_inputs)
            text_features = text_features / text_features.norm(p=2, dim=-1, keepdim=True)
            logit_scale = model.logit_scale.exp().to(device)

        # æ¨ç†
        print("ğŸ” å¼€å§‹æ¨ç†...")
        all_predictions = []
        all_targets = []
        
        start_time = time.time()
        
        to_pil = transforms.ToPILImage() if dataset_name == "mnist" else None
        for batch_idx, (images, targets) in enumerate(tqdm(dataloader, desc=f"è¯„ä¼° {dataset_name}")):
            with torch.no_grad():
                # ç¼–ç å›¾åƒç‰¹å¾
                if dataset_name == "mnist":
                    if isinstance(images, torch.Tensor):
                        images_pil = [to_pil(img.cpu()) for img in images]
                    else:
                        images_pil = images
                    image_inputs = processor(images=images_pil, return_tensors="pt")
                    image_inputs = {k: v.to(device) for k, v in image_inputs.items()}
                    image_features = model.get_image_features(**image_inputs)
                else:
                    # å…¶ä»–æ•°æ®é›†çš„å›¾åƒå·²ç»é¢„å¤„ç†è¿‡äº†ï¼Œç›´æ¥ä¼ å…¥æ¨¡å‹
                    image_features = model.get_image_features(pixel_values=images.to(device))
                image_features = image_features / image_features.norm(p=2, dim=-1, keepdim=True)
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                logits = (image_features @ text_features.T) * logit_scale
                similarities = logits.softmax(dim=-1)
                
                # è·å–é¢„æµ‹ç»“æœï¼Œç¡®ä¿kä¸è¶…è¿‡ç±»åˆ«æ•°é‡
                actual_top_k = min(top_k, similarities.size(-1))
                _, predictions = similarities.topk(actual_top_k, dim=-1)
                
                all_predictions.append(predictions)
                all_targets.append(targets.to(device))
        
        inference_time = time.time() - start_time
        
        # åˆå¹¶ç»“æœ
        all_predictions = torch.cat(all_predictions, dim=0)
        all_targets = torch.cat(all_targets, dim=0)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(all_predictions, all_targets, top_k, len(class_names))
        
        # å‡†å¤‡ç»“æœ
        result = {
            "dataset": dataset_name,
            "num_samples": len(dataset),
            "num_classes": len(class_names),
            "inference_time": inference_time,
            "samples_per_second": len(dataset) / inference_time,
            **metrics
        }
        
        print(f"âœ… {dataset_name} è¯„ä¼°å®Œæˆ")
        print(f"ğŸ“Š Top-1 å‡†ç¡®ç‡: {metrics['top1_accuracy']:.4f}")
        print(f"ğŸ“Š Top-{top_k} å‡†ç¡®ç‡: {metrics[f'top{top_k}_accuracy']:.4f}")
        print(f"â±ï¸  æ¨ç†æ—¶é—´: {inference_time:.2f} ç§’")
        print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {len(dataset) / inference_time:.2f} æ ·æœ¬/ç§’")
        
        return result
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°æ•°æ®é›† {dataset_name} æ—¶å‡ºé”™: {str(e)}")
        return {
            "dataset": dataset_name,
            "error": str(e),
            "status": "failed"
        }


def save_results(results: List[Dict[str, Any]], output_dir: str) -> None:
    """ä¿å­˜è¯„ä¼°ç»“æœ"""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    results_file = os.path.join(output_dir, f"clip_evaluation_{timestamp}.json")
    
    # æ·»åŠ æ‘˜è¦ä¿¡æ¯
    summary = {
        "timestamp": timestamp,
        "total_datasets": len(results),
        "successful_evaluations": len([r for r in results if "error" not in r]),
        "failed_evaluations": len([r for r in results if "error" in r]),
        "results": results
    }
    
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“‹ è¯„ä¼°æ‘˜è¦:")
    print(f"æ€»æ•°æ®é›†æ•°: {summary['total_datasets']}")
    print(f"æˆåŠŸè¯„ä¼°: {summary['successful_evaluations']}")
    print(f"å¤±è´¥è¯„ä¼°: {summary['failed_evaluations']}")
    
    if summary['successful_evaluations'] > 0:
        print("\nğŸ† æœ€ä½³ç»“æœ:")
        successful_results = [r for r in results if "error" not in r]
        successful_results.sort(key=lambda x: x.get("top1_accuracy", 0), reverse=True)
        
        for i, result in enumerate(successful_results[:5]):
            print(f"{i+1}. {result['dataset']}: {result.get('top1_accuracy', 0):.4f}")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = setup_device(args.device)
    
    # è®¾ç½®æ•°æ®ç±»å‹
    dtype = setup_dtype(args.dtype, device)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    create_directories(args.output_dir)
    
    # è§£ææ•°æ®é›†åˆ—è¡¨
    if args.datasets.lower() == "all":
        dataset_names = list(DATASET_CLASSES.keys())
    else:
        dataset_names = [name.strip() for name in args.datasets.split(",")]
    
    print(f"ğŸ¯ å°†è¯„ä¼°ä»¥ä¸‹æ•°æ®é›†: {', '.join(dataset_names)}")
    
    # åŠ è½½ CLIP æ¨¡å‹
    print("\nğŸ¤– åŠ è½½ CLIP æ¨¡å‹...")
    try:
        model, processor = load_clip_model(args.model_root, device, dtype)
    except Exception as e:
        print(f"âŒ åŠ è½½ CLIP æ¨¡å‹å¤±è´¥: {str(e)}")
        return
    
    # è¯„ä¼°æ‰€æœ‰æ•°æ®é›†
    results = []
    for dataset_name in dataset_names:
        result = evaluate_dataset(
            model=model,
            processor=processor,
            dataset_name=dataset_name,
            data_root=args.data_root,
            batch_size=args.batch_size,
            num_workers=args.num_workers,
            device=device,
            limit=args.limit,
            top_k=args.top_k
        )
        results.append(result)
    
    # ä¿å­˜ç»“æœ
    save_results(results, args.output_dir)
    
    print("\nğŸ‰ è¯„ä¼°å®Œæˆ!")


if __name__ == "__main__":
    main()
